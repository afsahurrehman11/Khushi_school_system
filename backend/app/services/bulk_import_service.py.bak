"""
Bulk Import Service with ZIP Image Support

Handles student bulk import with optional ZIP file containing student images.
Memory-safe: Uses streaming unzip and processes images one-by-one.
Images stored as base64 blobs directly in MongoDB.
"""

import os
import tempfile
import shutil
import zipfile
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path

from app.database import get_db
from app.services.image_service import ImageService
from app.services.excel_service import build_student_doc
from app.utils.student_id_utils import generate_imported_student_id

logger = logging.getLogger(__name__)

# Constants
MAX_ZIP_SIZE = 50 * 1024 * 1024  # 50 MB
ALLOWED_IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png'}


def validate_zip_file_path(zip_path: str) -> Tuple[bool, str]:
    """
    Validate ZIP file size and integrity.
    
    Args:
        zip_content: ZIP file bytes
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    try:
        size = os.path.getsize(zip_path)
        if size > MAX_ZIP_SIZE:
            size_mb = size / (1024 * 1024)
            logger.error(f"游댮 [BULK] ZIP too large: {size_mb:.1f}MB (max 50MB)")
            return False, f"ZIP file too large ({size_mb:.1f}MB). Maximum allowed: 50MB"

        # Try to open as ZIP to validate integrity
        with zipfile.ZipFile(zip_path, 'r') as zf:
            # Check for any corrupted files
            bad_file = zf.testzip()
            if bad_file:
                logger.error(f"游댮 [BULK] Corrupted file in ZIP: {bad_file}")
                return False, f"ZIP contains corrupted file: {bad_file}"
    except zipfile.BadZipFile:
        logger.error("游댮 [BULK] Invalid ZIP file")
        return False, "Invalid or corrupted ZIP file"
    except Exception as e:
        logger.error(f"游댮 [BULK] ZIP validation error: {str(e)}")
        return False, f"ZIP validation failed: {str(e)}"
    
    return True, ""


def extract_zip_streaming_from_path(zip_path: str, extract_dir: str) -> Dict[str, str]:
    """
    Extract ZIP to temp directory using streaming to avoid memory overload.
    
    Args:
        zip_content: ZIP file bytes
        extract_dir: Directory to extract to
        
    Returns:
        Dict mapping lowercase filename to full path
    """
    image_map = {}
    
    with zipfile.ZipFile(zip_path, 'r') as zf:
        for file_info in zf.infolist():
            # Skip directories
            if file_info.is_dir():
                continue
            
            # Skip hidden files
            filename = file_info.filename
            if filename.startswith('.') or '/__MACOSX' in filename:
                continue
            
            # Get just the filename without path
            base_filename = os.path.basename(filename)
            if not base_filename:
                continue
            
            # Check if valid image extension
            ext = os.path.splitext(base_filename)[1].lower()
            if ext not in ALLOWED_IMAGE_EXTENSIONS:
                continue
            
            # Extract file
            extract_path = os.path.join(extract_dir, base_filename)
            
            # Stream extract to avoid memory issues
            with zf.open(file_info) as source, open(extract_path, 'wb') as target:
                shutil.copyfileobj(source, target)
            
            # Map lowercase name to path
            image_map[base_filename.lower()] = extract_path
            logger.debug(f"游댯 [BULK] Extracted: {base_filename}")
    
    logger.info(f"游릭 [BULK] Extracted {len(image_map)} images")
    return image_map

def process_bulk_import_with_images(
    valid_rows: List[Dict],
    zip_path: Optional[str],
    school_id: str,
    db
) -> Tuple[int, int, List[Dict], int, int]:
    """
    Process validated rows and import students with images.
    
    Args:
        valid_rows: List of validated student data rows
        zip_content: Optional ZIP file bytes containing images
        school_id: School ID for isolation
        db: Database instance
        
    Returns:
        Tuple of (success_count, fail_count, errors, images_uploaded, images_failed)
    """
    success_count = 0
    fail_count = 0
    errors: List[Dict] = []
    images_uploaded = 0
    images_failed = 0
    
    temp_dir = None
    image_map = {}
    
    try:
        # Extract ZIP if provided (path-based, streamed)
        if zip_path:
            logger.info("游댯 [BULK] Extracting ZIP file from path...")
            
            # Create temp directory
            temp_dir = tempfile.mkdtemp(prefix="student_import_")
            logger.info(f"游댯 [BULK] Temp directory: {temp_dir}")
            
            # Extract images
            image_map = extract_zip_streaming_from_path(zip_path, temp_dir)
        
        # Process each student row
        for row in valid_rows:
            row_num = row.get("row_num", 0)
            student_name = row.get("full_name", "Unknown")
            image_name = row.get("image_name", "")
            class_id = row.get("class_id", "")
            
            try:
                logger.info(f"游릭 [STUDENT] Creating: {student_name}")
                
                # Ensure class exists (create if not)
                if class_id:
                    existing_class = db.classes.find_one({
                        "school_id": school_id,
                        "$or": [
                            {"class_id": class_id},
                            {"name": class_id},
                            {"class_name": class_id}
                        ]
                    })
                    
                    if not existing_class:
                        # Create new class
                        new_class = {
                            "school_id": school_id,
                            "class_id": class_id,
                            "name": class_id,
                            "class_name": class_id,
                            "subjects": [],
                            "teacher_ids": [],
                            "created_at": datetime.utcnow(),
                            "updated_at": datetime.utcnow(),
                        }
                        db.classes.insert_one(new_class)
                        logger.info(f"游릭 [CLASS] Auto-created class: {class_id}")
                
                # Build student document
                doc = build_student_doc(row)
                doc["school_id"] = school_id
                
                # Check for image - store as blob
                image_blob = None
                image_type = None
                
                # Try to match image by registration_number or roll_number
                reg_number = row.get("registration_number", "")
                roll_number = row.get("roll_number", "")
                
                if image_map:
                    # Try multiple image name patterns
                    possible_names = [
                        image_name.lower() if image_name else None,
                        f"{reg_number}.jpg".lower() if reg_number else None,
                        f"{reg_number}.jpeg".lower() if reg_number else None,
                        f"{reg_number}.png".lower() if reg_number else None,
                        f"{roll_number}.jpg".lower() if roll_number else None,
                        f"{roll_number}.jpeg".lower() if roll_number else None,
                        f"{roll_number}.png".lower() if roll_number else None,
                    ]
                    
                    image_path = None
                    matched_name = None
                    for name in possible_names:
                        if name and name in image_map:
                            image_path = image_map[name]
                            matched_name = name
                            break
                    
                    if image_path and os.path.exists(image_path):
                        logger.info(f"游댯 [UPLOAD] Processing image: {matched_name}")
                        
                        # Read image file
                        with open(image_path, 'rb') as f:
                            image_content = f.read()
                        
                        # Process and convert to base64 blob
                        image_blob, image_type, error = ImageService.process_and_store(
                            image_content,
                            max_dimension=800,
                            quality=85
                        )
                        
                        if image_blob:
                            images_uploaded += 1
                            logger.info(f"游릭 [UPLOAD] Image processed: {matched_name}")
                        else:
                            images_failed += 1
                            logger.error(f"游댮 [UPLOAD] Failed: {matched_name} - {error}")
                            # Don't add to errors - image is optional
                    elif image_name:
                        # Only log if image was explicitly specified but not found
                        images_failed += 1
                        logger.warning(f"丘멆잺 [UPLOAD] Image not found: {image_name}")
                
                # Add image data to document if processed
                if image_blob:
                    doc["profile_image_blob"] = image_blob
                    doc["profile_image_type"] = image_type
                    doc["image_uploaded_at"] = datetime.utcnow()
                    doc["embedding_status"] = "pending"
                
                # Insert student into database
                result = db.students.insert_one(doc)
                
                if result.inserted_id:
                    success_count += 1
                    logger.info(f"游릭 [STUDENT] Created: {doc.get('student_id')} - {student_name}")
                else:
                    fail_count += 1
                    logger.error(f"游댮 [STUDENT] Failed to create: {student_name}")
                    errors.append({
                        "row": row_num,
                        "column": "Student",
                        "value": student_name,
                        "reason": "Failed to save student to database",
                        "status": "skipped"
                    })
                    
            except Exception as e:
                fail_count += 1
                logger.error(f"游댮 [STUDENT] Error creating {student_name}: {str(e)}")
                errors.append({
                    "row": row_num,
                    "column": "Student",
                    "value": student_name,
                    "reason": f"An error occurred: {str(e)}",
                    "status": "skipped"
                })
        
        logger.info(f"游릭 [BULK] Imported {success_count}/{len(valid_rows)} students")
        logger.info(f"游릭 [BULK] Images: {images_uploaded} uploaded, {images_failed} failed")
        
    finally:
        # Clean up temp directory
        if temp_dir and os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir)
                logger.info(f"游릭 [BULK] Cleaned up temp directory")
            except Exception as e:
                logger.warning(f"丘멆잺 [BULK] Failed to clean temp directory: {str(e)}")
    
    return success_count, fail_count, errors, images_uploaded, images_failed

def execute_import_with_images(
    rows_to_insert: List[Dict],
    rows_to_update: List[Dict],
    duplicate_action: str,
    db,
    school_id: str,
    zip_path: Optional[str] = None
) -> Tuple[int, int, List[Dict]]:
    """
    Execute the import with optional image processing.
    Wraps process_bulk_import_with_images for the background import flow.
    
    Args:
        rows_to_insert: New student rows to insert
        rows_to_update: Existing student rows to update (if duplicate_action == 'update')
        duplicate_action: 'skip' or 'update'
        db: Database instance
        school_id: School ID for isolation
        zip_content: Optional ZIP file bytes
        
    Returns:
        Tuple of (success_count, fail_count, errors)
    """
    all_errors: List[Dict] = []
    total_success = 0
    total_fail = 0
    
    # Generate proper student_id for each row
    for row in rows_to_insert:
        excel_id = row.get("student_id", "")
        row["student_id"] = generate_imported_student_id(excel_id)
        row["admission_year"] = 0  # For imported students
    
    # Process new insertions
    if rows_to_insert:
        success, fail, errors, _, _ = process_bulk_import_with_images(
            rows_to_insert,
            zip_path,
            school_id,
            db
        )
        total_success += success
        total_fail += fail
        all_errors.extend(errors)
    
    # Handle updates if needed
    if duplicate_action == "update" and rows_to_update:
        from bson import ObjectId
        
        for row in rows_to_update:
            try:
                existing_id = row.get("_existing_id")
                if not existing_id:
                    continue
                
                doc = build_student_doc(row)
                doc.pop("created_at", None)
                doc["updated_at"] = datetime.utcnow()
                
                db.students.update_one(
                    {"_id": ObjectId(existing_id)},
                    {"$set": doc}
                )
                total_success += 1
                logger.info(f"游릭 [STUDENT] Updated: {row.get('full_name')}")
                
            except Exception as e:
                total_fail += 1
                all_errors.append({
                    "row": row.get("row_num", 0),
                    "column": "Student",
                    "value": row.get("full_name", "Unknown"),
                    "reason": f"Update failed: {str(e)}"
                })
    
    return total_success, total_fail, all_errors
